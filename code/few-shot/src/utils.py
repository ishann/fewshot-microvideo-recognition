from prototypical_batch_sampler import PrototypicalBatchSampler
from dataset import EmbeddingDataset #, OmniglotDataset
from network import EmbeddingNet

import ipdb

import torch
import numpy as np

def init_seed(opt):
    '''
    Disable cudnn to maximize reproducibility
    '''
    torch.cuda.cudnn_enabled = False
    np.random.seed(opt.manual_seed)
    torch.manual_seed(opt.manual_seed)
    torch.cuda.manual_seed(opt.manual_seed)


#def init_dataset(opt, mode):
#    dataset = OmniglotDataset(mode=mode, root=opt.dataset_root)
#    n_classes = len(np.unique(dataset.y))
#    if n_classes < opt.classes_per_it_tr or n_classes < opt.classes_per_it_val:
#        raise(Exception('There are not enough classes in the dataset in order ' +
#                        'to satisfy the chosen classes_per_it. Decrease the ' +
#                        'classes_per_it_{tr/val} option and try again.'))
#    return dataset


def init_embedding_dataset(opt, mode):
    dataset = EmbeddingDataset(mode=mode, root=opt.dataset_root)
    n_classes = len(np.unique(dataset.y))
    if n_classes < opt.classes_per_it_tr or n_classes < opt.classes_per_it_val:
        raise(Exception('There are not enough classes in the dataset in order ' +
                        'to satisfy the chosen classes_per_it. Decrease the ' +
                        'classes_per_it_{tr/val} option and try again.'))
    return dataset


#def init_sampler(opt, labels, mode):
#    if 'train' in mode:
#        classes_per_it = opt.classes_per_it_tr
#        num_samples = opt.num_support_tr + opt.num_query_tr
#    else:
#        classes_per_it = opt.classes_per_it_val
#        num_samples = opt.num_support_val + opt.num_query_val
#
#    return PrototypicalBatchSampler(labels=labels,
#                                    classes_per_it=classes_per_it,
#                                    num_samples=num_samples,
#                                    iterations=opt.iterations)


def init_embedding_sampler(opt, labels, mode):
    if mode=="trn":
        classes_per_it = opt.classes_per_it_tr
        num_samples = opt.num_support_tr + opt.num_query_tr
    else:
        classes_per_it = opt.classes_per_it_val
        num_samples = opt.num_support_val + opt.num_query_val

    return PrototypicalBatchSampler(labels=labels,
                                    classes_per_it=classes_per_it,
                                    num_samples=num_samples,
                                    iterations=opt.iterations)


def init_embedding_dataloader(opt, mode):
    #ipdb.set_trace()
    dataset = init_embedding_dataset(opt, mode)
    sampler = init_embedding_sampler(opt, dataset.y, mode)
    dataloader = torch.utils.data.DataLoader(dataset, batch_sampler=sampler)
    return dataloader


#def init_dataloader(opt, mode):
#    #ipdb.set_trace()
#    dataset = init_dataset(opt, mode)
#    sampler = init_sampler(opt, dataset.y, mode)
#    dataloader = torch.utils.data.DataLoader(dataset, batch_sampler=sampler)
#    return dataloader


#def init_protonet(opt):
#    '''
#    Initialize the ProtoNet
#    '''
#    device = 'cuda:0' if torch.cuda.is_available() and opt.cuda else 'cpu'
#    model = ProtoNet().to(device)
#    return model


def init_embeddingnet(opt):
    '''
    Initialize EmbeddingNet.
    '''
    device = 'cuda:0' if torch.cuda.is_available() and opt.cuda else 'cpu'
    model = EmbeddingNet().to(device)
    return model


def init_optim(opt, model):
    '''
    Initialize optimizer
    '''
    return torch.optim.Adam(params=model.parameters(),
                            lr=opt.learning_rate)


def init_lr_scheduler(opt, optim):
    '''
    Initialize the learning rate scheduler
    '''
    return torch.optim.lr_scheduler.StepLR(optimizer=optim,
                                           gamma=opt.lr_scheduler_gamma,
                                           step_size=opt.lr_scheduler_step)


def save_list_to_file(path, thelist):
    with open(path, 'w') as f:
        for item in thelist:
            f.write("%s\n" % item)



